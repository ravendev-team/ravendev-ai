## Made by : ravendev ( dwfree74@naver.com / elca6659@gmail.com)
##           https://github.com/ravendev-team/ravendev-ai 
#
# pip install torch torchvision pillow numpy
#
# **ë§ˆìŠ¤í¬ íŒ½ì°½ â†’ í…ì„œ ë³€í™˜ â†’ ì¸í˜ì¸íŒ… â†’ í›„ì²˜ë¦¬(ì›ë³¸ ì˜ì—­ ë³´ì¡´ + ë¸”ëŸ¬ë§)**ê¹Œì§€ í†µí•©í•œ ì˜ˆì œ ì½”ë“œ
#
# ì£¼ìš” íŠ¹ì§•
#   ë§ˆìŠ¤í¬ íŒ½ì°½ìœ¼ë¡œ ì”ìƒ ì˜ì—­ ë„“í˜€ì„œ ë” í™•ì‹¤íˆ ì œê±° ìœ ë„
#   ì…ë ¥ í…ì„œ 16ë°°ìˆ˜ íŒ¨ë”©ìœ¼ë¡œ ëª¨ë¸ í¬ê¸° ìš”êµ¬ì‚¬í•­ ëŒ€ì‘
#   ì¶œë ¥ íŒ¨ë”© ì œê±° í›„ ì›ë³¸ ì´ë¯¸ì§€ ì˜ì—­ ìœ ì§€ â†’ ë§ˆìŠ¤í¬ ë°–ì€ ì›ë³¸ ìœ ì§€
#   ê²½ê³„ ë¸”ëŸ¬ë§ìœ¼ë¡œ ì”ìƒ ê²½ê³„ ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬
#   ë¸”ëŸ¬ ê°•ë„(alpha)ì™€ íŒ½ì°½ ì»¤ë„ í¬ê¸°(kernel)ëŠ” í•„ìš”ì— ë”°ë¼ ì¡°ì ˆ ê°€ëŠ¥
#########################################################################
# input íŒŒì¼ "input/background.png", "input/mask.png"
# input\background.png  ë³µì›ì‹œí‚¬ ë°°ê²½ì´ë¯¸ì§€
# input\mask.png  ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ (ë°°ê²½ê³¼ ê°ì²´ ì¤‘ ê°ì²´ì— ëŒ€í•œ ë§ˆìŠ¤í¬ì„)
# ë‹¤ìš´ë¡œë“œíŒŒì¼ : https://huggingface.co/spaces/aryadytm/remove-photo-object/blob/f00f2d12ada635f5f30f18ed74200ea89dd26631/assets/big-lama.pt
# models\big-lama.pt
# config\lama.yaml
#########################################################################
import torch
import cv2
import numpy as np
from PIL import Image

def inpaint_with_lama(image_path, mask_path, model_path="models/big-lama.pt", output_path="lama_output.png"):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1. ì´ë¯¸ì§€ & ë§ˆìŠ¤í¬ ì½ê¸°
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    # 2. ë§ˆìŠ¤í¬ íŒ½ì°½ (ì”ìƒ ì œê±° ë„ì›€)
    kernel = np.ones((7,7), np.uint8)  # ì»¤ë„ í¬ê¸° ì¡°ì ˆ ê°€ëŠ¥
    mask_dilated = cv2.dilate(mask, kernel, iterations=1)

    # 3. ë§ˆìŠ¤í¬ í¬ê¸° ì´ë¯¸ì§€ì— ë§ì¶¤
    mask_dilated = cv2.resize(mask_dilated, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)

    # 4. í…ì„œ ë³€í™˜ ë° ì •ê·œí™”
    image_tensor = torch.from_numpy(image).float().permute(2, 0, 1) / 255.0
    mask_tensor = torch.from_numpy(mask_dilated).float().unsqueeze(0) / 255.0

    image_tensor = image_tensor.unsqueeze(0).to(device)
    mask_tensor = mask_tensor.unsqueeze(0).to(device)

    # 5. ì…ë ¥ í…ì„œ íŒ¨ë”© í•¨ìˆ˜ (16 ë°°ìˆ˜)
    def pad_to_multiple(t, multiple=16):
        _, _, h, w = t.shape
        pad_h = (multiple - h % multiple) % multiple
        pad_w = (multiple - w % multiple) % multiple
        padding = (0, pad_w, 0, pad_h)  # (left, right, top, bottom)
        return torch.nn.functional.pad(t, padding), padding

    image_tensor, img_pad = pad_to_multiple(image_tensor, 16)
    mask_tensor, mask_pad = pad_to_multiple(mask_tensor, 16)

    # 6. ëª¨ë¸ ë¡œë“œ
    print("ğŸ” Loading LaMa model...")
    model = torch.jit.load(model_path, map_location=device).eval()
    print("âœ… Model loaded!")

    # 7. ì¸í˜ì¸íŒ… ì¶”ë¡ 
    with torch.no_grad():
        output = model(image_tensor, mask_tensor)

    # 8. íŒ¨ë”© ì œê±°
    h_pad = img_pad[3]
    w_pad = img_pad[1]
    if h_pad > 0 or w_pad > 0:
        output = output[:, :, :-h_pad if h_pad > 0 else None, :-w_pad if w_pad > 0 else None]

    output_image = output[0].permute(1, 2, 0).cpu().numpy()
    output_image = (output_image * 255).clip(0, 255).astype(np.uint8)

    # 9. í›„ì²˜ë¦¬: ì›ë³¸ ì˜ì—­ ë³´ì¡´
    mask_binary = (mask_dilated > 127).astype(np.uint8)
    result = output_image.copy()
    result[mask_binary == 0] = image[mask_binary == 0]

    # 10. í›„ì²˜ë¦¬: ê²½ê³„ ë¶€ë“œëŸ½ê²Œ ë¸”ëŸ¬ (ì˜µì…˜)
    blurred = cv2.GaussianBlur(result, (7,7), 0)
    alpha = 0.3  # ë¸”ëŸ¬ ê°•ë„, 0 ~ 1 ì‚¬ì´
    result = cv2.addWeighted(result, 1 - alpha, blurred, alpha, 0)

    # 11. ê²°ê³¼ ì €ì¥ (RGB â†’ PIL)
    Image.fromarray(result).save(output_path)
    print(f"ğŸ–¼ï¸ ë³µì› ê²°ê³¼ ì €ì¥: {output_path}")


if __name__ == "__main__":
    inpaint_with_lama("input/background.png", "input/debug_full_mask.png")

